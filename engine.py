import pandas as pd
import io
import unicodedata
import re

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
OUTSIDE = "—à–ª—é–∑"
INSIDE_HINT = "–æ—Ñ–∏—Å"
DEDUP_WINDOW_MIN = 3        # —Å–ª–∏–ø–∞–Ω–∏–µ –¥—É–±–ª–µ–π (–º–∏–Ω—É—Ç—ã)
CORE_START_H, CORE_START_M = 9, 0
CORE_END_H,   CORE_END_M   = 18, 0
DAY_CORE_MIN = 8 * 60       # 8 —á–∞—Å–æ–≤ —è–¥—Ä–∞
LATE_H, LATE_M = 9, 1       # –æ–ø–æ–∑–¥–∞–Ω–∏–µ —Å 09:01


def fmt_hm(m) -> str:
    """–º–∏–Ω—É—Ç—ã -> 'X—á Y–º–∏–Ω' (0 -> '0—á 0–º–∏–Ω', –ø—É—Å—Ç–æ–µ –µ—Å–ª–∏ NaN)."""
    if m is None or pd.isna(m):
        return ""
    try:
        m = int(m)
    except Exception:
        return ""
    if m < 0:
        m = 0
    h, mm = divmod(m, 60)
    return f"{h}—á {mm}–º–∏–Ω"


def fio_norm(s: str) -> str:
    s = "" if pd.isna(s) else str(s)
    s = unicodedata.normalize("NFKC", s)
    s = s.replace("—ë", "–µ").replace("–Å", "–ï")
    s = " ".join(s.strip().split()).lower()
    return s


def work_day(ts):
    """–†–∞–±–æ—á–∏–µ —Å—É—Ç–∫–∏ 06:00‚Äì06:00."""
    ts = pd.to_datetime(ts)
    return (ts - pd.Timedelta(days=1)).date() if ts.hour < 6 else ts.date()


def norm(s):
    s = "" if pd.isna(s) else str(s)
    return unicodedata.normalize("NFKC", s).strip().casefold()


def inside_minutes_between(
    grp: pd.DataFrame,
    right_col: str,
    a: pd.Timestamp,
    b: pd.Timestamp,
) -> int:
    """
    –°–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –±—ã–ª –í–ù–£–¢–†–ò –æ—Ñ–∏—Å–∞ –≤ –æ–∫–Ω–µ [a, b].
    –û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö (–æ—Ñ–∏—Å/—à–ª—é–∑).
    """
    if grp is None or grp.empty or a >= b:
        return 0

    g = grp.sort_values("–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è")[[ "–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è", right_col ]].copy()
    g["dest_n"] = g[right_col].map(norm)

    start_look = a - pd.Timedelta(hours=6)
    sec = g[(g["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"] >= start_look) & (g["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"] <= b)].copy()
    sec["label"] = sec["dest_n"].apply(
        lambda s: "in" if INSIDE_HINT in s else ("out" if OUTSIDE in s else None)
    )
    sec = sec.dropna(subset=["label"]).reset_index(drop=True)

    # —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞ –º–æ–º–µ–Ω—Ç a
    hist = g[g["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"] <= a]
    last_dest = hist.iloc[-1]["dest_n"] if len(hist) else ""
    inside = OUTSIDE not in last_dest

    # –¥–µ–¥—É–ø –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –ø–æ–¥—Ä—è–¥ –º–µ—Ç–æ–∫
    ded = []
    for _, row in sec.iterrows():
        t, lab = row["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"], row["label"]
        if ded:
            t_prev, lab_prev = ded[-1]
            if lab == lab_prev and (t - t_prev).total_seconds() / 60.0 <= DEDUP_WINDOW_MIN:
                continue
        ded.append((t, lab))

    mins = 0.0
    last_t = a
    for t, lab in ded:
        t_clamp = min(max(t, a), b)
        if inside:
            mins += max(0.0, (t_clamp - last_t).total_seconds() / 60.0)
        inside = lab == "in"
        last_t = t_clamp
        if last_t >= b:
            break

    if last_t < b and inside:
        mins += (b - last_t).total_seconds() / 60.0

    return int(round(mins))


def longest_outside_gap_between(
    grp: pd.DataFrame,
    right_col: str,
    a: pd.Timestamp,
    b: pd.Timestamp,
):
    """
    –°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª '–≤–Ω–µ –æ—Ñ–∏—Å–∞' –≤ –æ–∫–Ω–µ [a,b].
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (gap_min, t_from, t_to).
    """
    if grp is None or grp.empty or a >= b:
        return 0, None, None

    g = grp.sort_values("–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è")[[ "–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è", right_col ]].copy()
    g["dest_n"] = g[right_col].map(norm)

    start_look = a - pd.Timedelta(hours=6)
    sec = g[(g["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"] >= start_look) & (g["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"] <= b)].copy()
    sec["label"] = sec["dest_n"].apply(
        lambda s: "in" if INSIDE_HINT in s else ("out" if OUTSIDE in s else None)
    )
    sec = sec.dropna(subset=["label"]).reset_index(drop=True)

    # —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞ –º–æ–º–µ–Ω—Ç a
    hist = g[g["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"] <= a]
    last_dest = hist.iloc[-1]["dest_n"] if len(hist) else ""
    outside = OUTSIDE in last_dest

    ded = []
    for _, row in sec.iterrows():
        t, lab = row["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"], row["label"]
        if ded:
            t_prev, lab_prev = ded[-1]
            if lab == lab_prev and (t - t_prev).total_seconds() / 60.0 <= DEDUP_WINDOW_MIN:
                continue
        ded.append((t, lab))

    best = 0.0
    best_a = None
    best_b = None
    last_t = a

    for t, lab in ded:
        t_clamp = min(max(t, a), b)
        if outside:
            gap = max(0.0, (t_clamp - last_t).total_seconds() / 60.0)
            if gap > best:
                best, best_a, best_b = gap, last_t, t_clamp
        outside = lab == "out"
        last_t = t_clamp
        if last_t >= b:
            break

    if last_t < b and outside:
        gap = (b - last_t).total_seconds() / 60.0
        if gap > best:
            best, best_a, best_b = gap, last_t, b

    return int(round(best)), best_a, best_b


def compute_outside_table(df: pd.DataFrame, right_col: str) -> pd.DataFrame:
    """
    –¢–∞–±–ª–∏—Ü–∞ ¬´–í–Ω–µ –æ—Ñ–∏—Å–∞¬ª –ø–æ –∫–∞–∂–¥–æ–º—É (–§–ò–û, –†–∞–±–æ—á–∏–π_–¥–µ–Ω—å).
    right_col = '–í—Ö–æ–¥' –∏–ª–∏ '–í—ã—Ö–æ–¥' ‚Äî –ø–æ –∫–∞–∫–æ–π –∫–æ–ª–æ–Ω–∫–µ —Å—á–∏—Ç–∞—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è.
    """
    rows = []

    for (fio, day), grp in df.groupby(["–§–ò–û", "–†–∞–±–æ—á–∏–π_–¥–µ–Ω—å"], sort=False):
        base = pd.Timestamp(day).normalize()
        start0600 = base + pd.Timedelta(hours=6)
        end0600 = start0600 + pd.Timedelta(days=1)

        first = grp["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"].min()
        last = grp["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"].max()

        # –æ–∫–Ω–æ —è–¥—Ä–∞ 09‚Äì18
        a = base + pd.Timedelta(hours=CORE_START_H, minutes=CORE_START_M)
        b = base + pd.Timedelta(hours=CORE_END_H,   minutes=CORE_END_M)
        a = max(a, start0600)
        b = min(b, end0600)

        if a >= b:
            out_core_min = 0
            gap_period = ""
        else:
            total_core = (b - a).total_seconds() / 60.0
            in_core = inside_minutes_between(grp, right_col, a, b)
            out_core_min = max(0.0, total_core - in_core)
            gap_min, g_a, g_b = longest_outside_gap_between(grp, right_col, a, b)
            gap_period = (
                f"{g_a:%H:%M}‚Äì{g_b:%H:%M}"
                if (gap_min and gap_min >= 120 and g_a and g_b)
                else ""
            )

        rows.append(
            {
                "–§–ò–û": fio,
                "–î–∞—Ç–∞": base.date(),
                "–í—Ä–µ–º—è –ø—Ä–∏—Ö–æ–¥–∞": first.strftime("%H:%M") if pd.notna(first) else "",
                "–í—Ä–µ–º—è —É—Ö–æ–¥–∞": last.strftime("%H:%M") if pd.notna(last) else "",
                "–í–Ω–µ_—è–¥—Ä–∞_–º–∏–Ω": int(round(out_core_min)),
                "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –±–æ–ª–µ–µ 2 —á–∞—Å–æ–≤ –ø–æ–¥—Ä—è–¥": gap_period,
            }
        )

    res = pd.DataFrame(rows).sort_values(["–§–ò–û", "–î–∞—Ç–∞"])
    res["–í–Ω–µ –æ—Ñ–∏—Å–∞"] = res["–í–Ω–µ_—è–¥—Ä–∞_–º–∏–Ω"].apply(lambda m: f"{m // 60}—á {m % 60}–º–∏–Ω")
    return res[
        [
            "–§–ò–û",
            "–î–∞—Ç–∞",
            "–í—Ä–µ–º—è –ø—Ä–∏—Ö–æ–¥–∞",
            "–í—Ä–µ–º—è —É—Ö–æ–¥–∞",
            "–í–Ω–µ –æ—Ñ–∏—Å–∞",
            "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –±–æ–ª–µ–µ 2 —á–∞—Å–æ–≤ –ø–æ–¥—Ä—è–¥",
            "–í–Ω–µ_—è–¥—Ä–∞_–º–∏–Ω",
        ]
    ]


# --- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è ¬´–Ω–µ –ª—é–¥–µ–π¬ª (–∫–∞—Ä—Ç—ã, –∫–ª–∏–Ω–∏–Ω–≥ –∏ —Ç.–ø.) ---
NONPERSON_TOKENS = [
    "—Å—Ç—É–¥–µ–Ω—Ç",
    "–∫–ª–∏–Ω–∏–Ω–≥",
    "—É–±–æ—Ä—â",
    "–≤–æ–¥–∏—Ç–µ–ª",
    "–æ—Ö—Ä–∞–Ω",
    "—Ç–µ—Ö–Ω–∏—á",
    "–ø–µ—Ä—Å–æ–Ω–∞–ª",
    "–∏–Ω–∂–µ–Ω–µ—Ä –±–µ–∑",
    "–±–µ–∑ —Ñ–∏–æ",
    "–±–µ–∑—Ñ–∏–æ",
    "–∞—ç—Ä–æ—Å—Ç–∞—Ä",
    "aerostar",
    "—Ç–µ—Ö–Ω–æ—Å–µ—Ä–≤–∏—Å",
    "—Ç–µ—Ö–Ω–æ-—Å–µ—Ä–≤–∏—Å",
    "—Ç–µ—Ö–Ω–æ—Å–µ—Ä–≤",
    "–æ—Ç–µ–ª—å",
    "–≥–æ—Å—Ç–∏–Ω–∏—Ü",
    "—Å—Ç–∞–∂–µ—Ä",
    "—Å—Ç–∞–∂—ë—Ä",
    "–ø—Ä–∞–∫—Ç–∏–∫–∞–Ω—Ç",
    "–∏–Ω—Ç–µ—Ä–Ω",
    "–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç",
    "—É—á–µ–Ω–∏–∫",
]
WHOLE_WORD_TOKENS = ["–æ–æ–æ", "–æ–∞–æ", "–ø–∞–æ", "–∑–∞–æ", "–∏–ø"]
EXCLUDE_NAME_ALIASES = {"–ø–µ–ª–µ—à–æ–∫", "–ø–µ—à–µ–ª–∫–∞"}


def is_nonperson(fio: str) -> bool:
    s = "" if fio is None else str(fio)
    s = unicodedata.normalize("NFKC", s).strip().casefold()
    if not s:
        return True
    if any(alias in s for alias in EXCLUDE_NAME_ALIASES):
        return True
    if any(tok in s for tok in NONPERSON_TOKENS):
        return True
    if re.search(r"\b(?:" + "|".join(map(re.escape, WHOLE_WORD_TOKENS)) + r")\b", s):
        return True
    if any(ch.isdigit() for ch in s):
        return True
    return False


def read_journal(file_obj) -> pd.DataFrame:
    """
    –ß–∏—Ç–∞–µ–º –∂—É—Ä–Ω–∞–ª –ø—Ä–æ—Ö–æ–¥–æ–≤ –∏–∑ Excel.
    –û–∂–∏–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏:
    ['–°–æ–±—ã—Ç–∏–µ','–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è','–§–∞–º–∏–ª–∏—è','–ò–º—è','–û—Ç—á–µ—Å—Ç–≤–æ','–í—Ö–æ–¥','–í—ã—Ö–æ–¥']
    """
    need = ["–°–æ–±—ã—Ç–∏–µ", "–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è", "–§–∞–º–∏–ª–∏—è", "–ò–º—è", "–û—Ç—á–µ—Å—Ç–≤–æ", "–í—Ö–æ–¥", "–í—ã—Ö–æ–¥"]

    content = file_obj.read()
    df_raw = None
    for skip in (3, 0, 1, 2):
        try:
            _tmp = pd.read_excel(io.BytesIO(content), engine="openpyxl", skiprows=skip)
            if set(need).issubset(_tmp.columns):
                df_raw = _tmp
                break
        except Exception:
            continue

    if df_raw is None:
        raise RuntimeError(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∂—É—Ä–Ω–∞–ª: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ "
            f"(–æ–∂–∏–¥–∞–ª–∏—Å—å: {need}). –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞."
        )

    df = df_raw[need].copy()
    df["–°–æ–±—ã—Ç–∏–µ_n"] = df["–°–æ–±—ã—Ç–∏–µ"].apply(norm)
    df = df[
        df["–°–æ–±—ã—Ç–∏–µ_n"].str.contains("–ø—Ä–æ—Ö–æ–¥ –ø–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É", na=False)
    ].copy()

    for c in ["–§–∞–º–∏–ª–∏—è", "–ò–º—è", "–û—Ç—á–µ—Å—Ç–≤–æ"]:
        df[c] = df[c].where(df[c].notna(), "").astype(str).str.strip()

    def _join_fio(row):
        parts = [row["–§–∞–º–∏–ª–∏—è"], row["–ò–º—è"], row["–û—Ç—á–µ—Å—Ç–≤–æ"]]
        return " ".join(p for p in parts if p)

    df["–§–ò–û"] = (
        df.apply(_join_fio, axis=1)
        .str.replace(r"\s+", " ", regex=True)
        .str.strip()
    )

    df["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"] = pd.to_datetime(df["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"], errors="coerce")
    df = df.dropna(subset=["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"]).sort_values("–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è")
    df["–†–∞–±–æ—á–∏–π_–¥–µ–Ω—å"] = df["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"].apply(work_day)

    df["–í—Ö–æ–¥_n"] = df["–í—Ö–æ–¥"].apply(norm)
    df["–í—ã—Ö–æ–¥_n"] = df["–í—ã—Ö–æ–¥"].apply(norm)
    ok = ~(
        df["–í—Ö–æ–¥_n"].str.contains("–Ω–µ–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º", na=False)
        | df["–í—ã—Ö–æ–¥_n"].str.contains("–Ω–µ–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º", na=False)
    )
    df = df[ok].copy()

    df = df[~df["–§–ò–û"].apply(is_nonperson)].copy()

    return df


def read_kadry(file_obj) -> pd.DataFrame:
    """
    –ß–∏—Ç–∞–µ–º –∫–∞–¥—Ä–æ–≤—ã–π —Ñ–∞–π–ª –∏ —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –≤ –ø–æ—Å—É—Ç–æ—á–Ω—ã–π —Å–ø–∏—Å–æ–∫.
    –û–∂–∏–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏: '–°–æ—Ç—Ä—É–¥–Ω–∏–∫', '–í–∏–¥ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è', '—Å', '–¥–æ'.
    """
    kadry = pd.read_excel(file_obj, header=None)

    # –∏—â–µ–º —Å—Ç—Ä–æ–∫—É, –≥–¥–µ –≤ –ª—é–±–æ–π –∫–æ–ª–æ–Ω–∫–µ –µ—Å—Ç—å '–°–æ—Ç—Ä—É–¥–Ω–∏–∫'
    def _is_sotr_cell(x):
        s = "" if pd.isna(x) else str(x)
        return s.strip().casefold() == "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫"

    mask_rows = kadry.apply(lambda row: row.map(_is_sotr_cell).any(), axis=1)
    idxs = kadry.index[mask_rows]
    if len(idxs) == 0:
        raise RuntimeError(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç—Ä–æ–∫—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º '–°–æ—Ç—Ä—É–¥–Ω–∏–∫' –≤ –∫–∞–¥—Ä–æ–≤–æ–º —Ñ–∞–π–ª–µ."
        )

    hdr_row = idxs[0]
    kadry.columns = kadry.iloc[hdr_row]
    kadry = kadry.iloc[hdr_row + 1 :]

    kadry = kadry.rename(
        columns={
            "–°–æ—Ç—Ä—É–¥–Ω–∏–∫": "–§–ò–û",
            "–í–∏–¥ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è": "–¢–∏–ø",
            "—Å": "–î–∞—Ç–∞_—Å",
            "–¥–æ": "–î–∞—Ç–∞_–ø–æ",
        }
    )
    kadry = kadry[["–§–ò–û", "–¢–∏–ø", "–î–∞—Ç–∞_—Å", "–î–∞—Ç–∞_–ø–æ"]].copy()
    kadry = kadry.dropna(subset=["–§–ò–û", "–¢–∏–ø"], how="any")

    for col in ["–î–∞—Ç–∞_—Å", "–î–∞—Ç–∞_–ø–æ"]:
        kadry[col] = kadry[col].astype(str).str.extract(
            r"(\d{2}\.\d{2}\.\d{4})", expand=False
        )
        kadry[col] = pd.to_datetime(kadry[col], dayfirst=True, errors="coerce")

    kadry["–î–∞—Ç–∞_–ø–æ"] = kadry["–î–∞—Ç–∞_–ø–æ"].fillna(kadry["–î–∞—Ç–∞_—Å"])

    rows = []
    for _, r in kadry.iterrows():
        d1, d2 = r["–î–∞—Ç–∞_—Å"], r["–î–∞—Ç–∞_–ø–æ"]
        if pd.isna(d1) or pd.isna(d2):
            continue
        for d in pd.date_range(d1, d2, freq="D"):
            rows.append({"–§–ò–û": r["–§–ò–û"], "–î–∞—Ç–∞": d.date(), "–¢–∏–ø": r["–¢–∏–ø"]})

    kadry_dates = pd.DataFrame(rows)

    # –∑–∞–º–µ–Ω–∞ ¬´–≥–æ—Å. –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏¬ª -> ¬´–°–¥–∞—á–∞ –∫—Ä–æ–≤–∏¬ª
    kadry_dates["–¢–∏–ø"] = kadry_dates["–¢–∏–ø"].replace(
        to_replace=r"(?i).*–≥–æ—Å.*–æ–±—è–∑–∞–Ω.*", value="–°–¥–∞—á–∞ –∫—Ä–æ–≤–∏", regex=True
    )

    return kadry_dates


# --- –î–æ–ø. –ª–æ–≥–∏–∫–∞: –æ–ø–æ–∑–¥–∞–Ω–∏—è, –≤—ã—Ö–æ–¥—ã, —Ñ–ª–∞–≥ "–≤–æ–∑–º–æ–∂–µ–Ω –ø—Ä–æ—Ö–æ–¥ –≤–Ω–µ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞" ---


def _core_window_for_day(day):
    base = pd.Timestamp(day).normalize()
    a = base + pd.Timedelta(hours=CORE_START_H, minutes=CORE_START_M)
    b = base + pd.Timedelta(hours=CORE_END_H, minutes=CORE_END_M)
    return a, b


def _calc_group_stats(df: pd.DataFrame):
    """
    –î–ª—è –∫–∞–∂–¥–æ–≥–æ (–§–ò–û, –†–∞–±–æ—á–∏–π_–¥–µ–Ω—å):
      - –ø–µ—Ä–≤—ã–π/–ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ—Ö–æ–¥
      - –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
      - –æ–ø–æ–∑–¥–∞–Ω–∏–µ / –≤–æ–≤—Ä–µ–º—è
    """
    rows = []
    for (fio, day), grp in df.groupby(["–§–ò–û", "–†–∞–±–æ—á–∏–π_–¥–µ–Ω—å"], sort=False):
        grp = grp.sort_values("–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è")
        first_ts = grp["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"].iloc[0]
        last_ts = grp["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"].iloc[-1]
        dur_min = int(
            (last_ts - first_ts).total_seconds() / 60.0
        ) if pd.notna(last_ts) and pd.notna(first_ts) else 0

        # –ø–æ—Ä–æ–≥ –æ–ø–æ–∑–¥–∞–Ω–∏—è 09:01
        plan_start = pd.Timestamp(day) + pd.Timedelta(hours=LATE_H, minutes=LATE_M)
        late_min = (
            first_ts - plan_start
        ).total_seconds() / 60.0 if pd.notna(first_ts) else 0
        status = "–æ–ø–æ–∑–¥–∞–Ω–∏–µ" if late_min > 0 else "–≤–æ–≤—Ä–µ–º—è"

        rows.append(
            {
                "–§–ò–û": fio,
                "–î–∞—Ç–∞": pd.to_datetime(day).date(),
                "first_ts": first_ts,
                "last_ts": last_ts,
                "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_–º–∏–Ω": max(dur_min, 0),
                "–û–ø–æ–∑–¥–∞–Ω–∏–µ": status,
            }
        )

    st = pd.DataFrame(rows)
    st["–û–±—â–µ–µ –≤—Ä–µ–º—è"] = st["–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_–º–∏–Ω"].apply(fmt_hm)
    return st


def _calc_exits_and_suspect(df: pd.DataFrame, right_col: str):
    """
    –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–Ω—è:
      - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–æ–≤ –≤ —è–¥—Ä–µ (09‚Äì18)
      - —Ñ–ª–∞–≥ 'suspect' (–≤–æ–∑–º–æ–∂–µ–Ω –ø—Ä–æ—Ö–æ–¥ –≤–Ω–µ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞)
    """
    rows = []

    for (fio, day), grp in df.groupby(["–§–ò–û", "–†–∞–±–æ—á–∏–π_–¥–µ–Ω—å"], sort=False):
        base = pd.Timestamp(day).normalize()
        a_core, b_core = _core_window_for_day(base)

        g = grp.sort_values("–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è")[[ "–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è", right_col ]].copy()
        g["dest_n"] = g[right_col].map(norm)

        # —Ç–æ–ª—å–∫–æ —Å–æ–±—ã—Ç–∏—è –≤ —è–¥—Ä–µ
        g = g[(g["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"] >= a_core) & (g["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"] <= b_core)]

        labels = []
        times = []
        for _, r in g.iterrows():
            s = r["dest_n"]
            lab = "in" if INSIDE_HINT in s else ("out" if OUTSIDE in s else None)
            if lab is None:
                continue
            t = r["–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è"]
            # –¥–µ–¥—É–ø –¥—Ä–æ–∂–∞–Ω–∏—è
            if labels:
                t_prev = times[-1]
                lab_prev = labels[-1]
                if (
                    lab == lab_prev
                    and (t - t_prev).total_seconds() / 60.0 <= DEDUP_WINDOW_MIN
                ):
                    continue
            labels.append(lab)
            times.append(t)

        # –≤—ã—Ö–æ–¥—ã: –ø–µ—Ä–µ—Ö–æ–¥ in -> out
        exits = 0
        for i in range(1, len(labels)):
            if labels[i - 1] == "in" and labels[i] == "out":
                exits += 1

        # suspect: –¥–≤–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –ø–æ–¥—Ä—è–¥ —Å–æ–±—ã—Ç–∏—è —Å —Ä–∞–∑—Ä—ã–≤–æ–º > DEDUP_WINDOW_MIN
        suspect = False
        for i in range(1, len(labels)):
            if labels[i] == labels[i - 1]:
                gap = (times[i] - times[i - 1]).total_seconds() / 60.0
                if gap > DEDUP_WINDOW_MIN:
                    suspect = True
                    break

        rows.append(
            {
                "–§–ò–û": fio,
                "–î–∞—Ç–∞": base.date(),
                "–í—ã—Ö–æ–¥—ã": exits,
                "suspect": suspect,
            }
        )

    return pd.DataFrame(rows)


def build_report(journal_file, kadry_file) -> pd.DataFrame:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ø–æ–ª—É—á–∞–µ—Ç –¥–≤–∞ —Ñ–∞–π–ª–∞ (–∂—É—Ä–Ω–∞–ª –∏ –∫–∞–¥—Ä—ã) –∏
    –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π pandas.DataFrame –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –≤ Excel.
    """
    # 1) —á–∏—Ç–∞–µ–º –∂—É—Ä–Ω–∞–ª
    df = read_journal(journal_file)

    # 2) –≤—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—É—é –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π ('–í—Ö–æ–¥' –∏–ª–∏ '–í—ã—Ö–æ–¥')
    def _total_outside(col):
        t = compute_outside_table(df, col)
        return pd.to_numeric(t["–í–Ω–µ_—è–¥—Ä–∞_–º–∏–Ω"], errors="coerce").fillna(0).sum()

    sum_exit = _total_outside("–í—ã—Ö–æ–¥")
    sum_entry = _total_outside("–í—Ö–æ–¥")
    right_col = "–í—Ö–æ–¥" if sum_entry <= sum_exit else "–í—ã—Ö–æ–¥"

    # 3) —Ç–∞–±–ª–∏—Ü–∞ "–≤–Ω–µ –æ—Ñ–∏—Å–∞"
    out_df = compute_outside_table(df, right_col)

    # 4) –æ–ø–æ–∑–¥–∞–Ω–∏—è –∏ –æ–±—â–µ–µ –≤—Ä–µ–º—è
    stats_df = _calc_group_stats(df)
    out_df = out_df.merge(
        stats_df[["–§–ò–û", "–î–∞—Ç–∞", "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_–º–∏–Ω", "–û–±—â–µ–µ –≤—Ä–µ–º—è", "–û–ø–æ–∑–¥–∞–Ω–∏–µ"]],
        on=["–§–ò–û", "–î–∞—Ç–∞"],
        how="left",
    )

    # 5) –≤—ã—Ö–æ–¥—ã –∏ —Ñ–ª–∞–≥ "–≤–æ–∑–º–æ–∂–µ–Ω –ø—Ä–æ—Ö–æ–¥ –≤–Ω–µ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞"
    ex_df = _calc_exits_and_suspect(df, right_col)
    out_df = out_df.merge(ex_df, on=["–§–ò–û", "–î–∞—Ç–∞"], how="left")
    out_df["–í—ã—Ö–æ–¥—ã"] = out_df["–í—ã—Ö–æ–¥—ã"].fillna(0).astype(int)

    # –¥–æ–±–∞–≤–ª—è–µ–º –Ω–∞–¥–ø–∏—Å—å –∫ "–í–Ω–µ –æ—Ñ–∏—Å–∞"
    note = "–≤–æ–∑–º. –ø—Ä–æ—Ö–æ–¥ –≤–Ω–µ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞"
    out_df["–í–Ω–µ –æ—Ñ–∏—Å–∞"] = out_df.apply(
        lambda r: f"{r['–í–Ω–µ –æ—Ñ–∏—Å–∞']}\n{note}" if bool(r.get("suspect", False)) else r["–í–Ω–µ –æ—Ñ–∏—Å–∞"],
        axis=1,
    )

    # 6) –¥–Ω–µ–≤–Ω–æ–π –∏—Ç–æ–≥ –∏ –Ω–µ–¥–æ—Ä–∞–±–æ—Ç–∫–∏
    dur = pd.to_numeric(out_df["–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å_–º–∏–Ω"], errors="coerce").fillna(0)

    # –æ–±–µ–¥: –µ—Å–ª–∏ —Å–º–µ–Ω–∞ >= 60 –º–∏–Ω ‚Äî 60 –º–∏–Ω—É—Ç, –∏–Ω–∞—á–µ 0
    lunch = dur.apply(lambda x: 60 if x >= 60 else 0)

    # —à—Ç—Ä–∞—Ñ –∑–∞ "–≤–Ω–µ —è–¥—Ä–∞": –±—É—Ñ–µ—Ä 60 –º–∏–Ω
    out_core = pd.to_numeric(out_df["–í–Ω–µ_—è–¥—Ä–∞_–º–∏–Ω"], errors="coerce").fillna(0)
    penalty = (out_core - 60).clip(lower=0)
    penalty = penalty.where(dur >= 60, 0)  # –µ—Å–ª–∏ —Å–º–µ–Ω–∞ < 60 –º–∏–Ω, –Ω–µ —à—Ç—Ä–∞—Ñ—É–µ–º

    # —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –≤—Ä–µ–º—è –∑–∞ –¥–µ–Ω—å
    eff_day = (dur - lunch - penalty).clip(lower=0)
    out_df["–ò—Ç–æ–≥–æ_–¥–Ω—è_–º–∏–Ω"] = eff_day.astype(int)
    out_df["–ò—Ç–æ–≥–æ –∑–∞ –¥–µ–Ω—å"] = out_df["–ò—Ç–æ–≥–æ_–¥–Ω—è_–º–∏–Ω"].apply(fmt_hm)

    # –Ω–µ–¥–æ—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —è–¥—Ä—É)
    out_df["–ù–µ–¥–æ—Ä–∞–±–æ—Ç–∫–∏_–º–∏–Ω"] = penalty.astype(int)
    out_df["–ù–µ–¥–æ—Ä–∞–±–æ—Ç–∫–∏"] = out_df["–ù–µ–¥–æ—Ä–∞–±–æ—Ç–∫–∏_–º–∏–Ω"].apply(
        lambda m: fmt_hm(m) if m > 0 else ""
    )

    # 7) –Ω–µ–¥–µ–ª—å–Ω—ã–π –∏—Ç–æ–≥ (–ø–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º –¥–Ω—è–º)
    out_df["–î–∞—Ç–∞_dt"] = pd.to_datetime(out_df["–î–∞—Ç–∞"])
    out_df["week_monday"] = out_df["–î–∞—Ç–∞_dt"] - out_df["–î–∞—Ç–∞_dt"].dt.weekday * pd.Timedelta(
        days=1
    )

    week_sums = (
        out_df.groupby(["–§–ò–û", "week_monday"])["–ò—Ç–æ–≥–æ_–¥–Ω—è_–º–∏–Ω"].sum().reset_index()
    )
    week_sums.rename(columns={"–ò—Ç–æ–≥–æ_–¥–Ω—è_–º–∏–Ω": "–ò—Ç–æ–≥–æ_–Ω–µ–¥_–º–∏–Ω"}, inplace=True)

    out_df = out_df.merge(
        week_sums, on=["–§–ò–û", "week_monday"], how="left"
    )

    # –î–ª—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏: –∑–∞–ø–æ–ª–Ω—è–µ–º "–ò—Ç–æ–≥–æ –∑–∞ –Ω–µ–¥–µ–ª—é" —Ç–æ–ª—å–∫–æ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º –¥–Ω–µ –Ω–µ–¥–µ–ª–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞
    out_df.sort_values(["–§–ò–û", "–î–∞—Ç–∞_dt"], inplace=True)
    out_df["–ò—Ç–æ–≥–æ –∑–∞ –Ω–µ–¥–µ–ª—é"] = ""

    for (fio, w), sub in out_df.groupby(["–§–ò–û", "week_monday"], sort=False):
        if sub.empty:
            continue
        idx_last = sub.index[-1]
        val = sub["–ò—Ç–æ–≥–æ_–Ω–µ–¥_–º–∏–Ω"].iloc[0]
        out_df.at[idx_last, "–ò—Ç–æ–≥–æ –∑–∞ –Ω–µ–¥–µ–ª—é"] = fmt_hm(val)

        # 8) –ø–æ–¥–º–µ—à–∏–≤–∞–µ–º –∫–∞–¥—Ä–æ–≤—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è
    kadry_dates = read_kadry(kadry_file)

    # ‚ùó –ë–µ—Ä—ë–º –∏–∑ –∫–∞–¥—Ä–æ–≤ —Ç–æ–ª—å–∫–æ —Ç–µ –¥–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –æ—Ç—á—ë—Ç–µ –ø–æ –ø—Ä–æ—Ö–æ–¥–∞–º
    valid_dates = out_df["–î–∞—Ç–∞_dt"].dt.date.unique()
    kadry_dates = kadry_dates[kadry_dates["–î–∞—Ç–∞"].isin(valid_dates)].copy()

    # –∫–ª—é—á–∏ –¥–ª—è —Å–∫–ª–µ–π–∫–∏
    out_df["–î–∞—Ç–∞_key"] = out_df["–î–∞—Ç–∞_dt"].dt.date
    kadry_dates["–î–∞—Ç–∞_key"] = kadry_dates["–î–∞—Ç–∞"]

    out_df["–§–ò–û_key"] = out_df["–§–ò–û"].astype(str).str.strip().str.lower()
    kadry_dates["–§–ò–û_key"] = kadry_dates["–§–ò–û"].astype(str).str.strip().str.lower()

    # –¥–æ–±–∞–≤–∏–º –≤ –∫–∞–¥—Ä—ã –∏—Å—Ö–æ–¥–Ω–æ–µ –§–ò–û, —á—Ç–æ–±—ã –ø–æ–¥—Ç—è–Ω—É—Ç—å –µ–≥–æ, –µ—Å–ª–∏ –ø—Ä–æ—Ö–æ–¥–æ–≤ –Ω–µ –±—ã–ª–æ
    kadry_merge = kadry_dates[["–§–ò–û_key", "–î–∞—Ç–∞_key", "–¢–∏–ø", "–§–ò–û"]].rename(
        columns={"–§–ò–û": "–§–ò–û_–∫–∞–¥—Ä—ã"}
    )

    # –í–ê–ñ–ù–û: –æ–±—ä–µ–¥–∏–Ω—è–µ–º "—Å–Ω–∞—Ä—É–∂–∏", —á—Ç–æ–±—ã –¥–Ω–∏ —Ç–æ–ª—å–∫–æ –∏–∑ –∫–∞–¥—Ä–æ–≤ —Ç–æ–∂–µ –ø–æ–ø–∞–ª–∏
    final = out_df.merge(
        kadry_merge,
        on=["–§–ò–û_key", "–î–∞—Ç–∞_key"],
        how="outer",
    )

    # –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –§–ò–û –∏ –¥–∞—Ç—É —Ç–∞–º, –≥–¥–µ –ø—Ä–æ—Ö–æ–¥–æ–≤ –Ω–µ –±—ã–ª–æ
    final["–§–ò–û"] = final["–§–ò–û"].fillna(final["–§–ò–û_–∫–∞–¥—Ä—ã"])
    final["–î–∞—Ç–∞_dt"] = final["–î–∞—Ç–∞_dt"].fillna(
        pd.to_datetime(final["–î–∞—Ç–∞_key"])
    )

    # –ø—Ä–∏—á–∏–Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ–π, –µ—Å–ª–∏ –ø—Ä–æ—Å—Ç–æ –æ–±—ã—á–Ω—ã–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å)
    final["–ü—Ä–∏—á–∏–Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è"] = final["–¢–∏–ø"]

    # 9) —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ—Å–º–µ—Ç–∏–∫–∞
    final["–î–∞—Ç–∞"] = final["–î–∞—Ç–∞_dt"].dt.strftime("%d-%m-%Y")

    # —á–∏—Å—Ç–∏–º NaN –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö, —á—Ç–æ–±—ã –≤ Excel –Ω–µ –±—ã–ª–æ "nan"
    for col in [
        "–û–ø–æ–∑–¥–∞–Ω–∏–µ",
        "–û–±—â–µ–µ –≤—Ä–µ–º—è",
        "–í–Ω–µ –æ—Ñ–∏—Å–∞",
        "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –±–æ–ª–µ–µ 2 —á–∞—Å–æ–≤ –ø–æ–¥—Ä—è–¥",
        "–ò—Ç–æ–≥–æ –∑–∞ –¥–µ–Ω—å",
        "–ò—Ç–æ–≥–æ –∑–∞ –Ω–µ–¥–µ–ª—é",
        "–ù–µ–¥–æ—Ä–∞–±–æ—Ç–∫–∏",
        "–ü—Ä–∏—á–∏–Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è",
    ]:
        if col in final.columns:
            final[col] = final[col].fillna("")

    # —á–∏—Å–ª–∞ –±–µ–∑ –ø—Ä–æ—Ö–æ–¥–æ–≤ = 0
    if "–í—ã—Ö–æ–¥—ã" in final.columns:
        final["–í—ã—Ö–æ–¥—ã"] = final["–í—ã—Ö–æ–¥—ã"].fillna(0).astype(int)
    if "–í–Ω–µ_—è–¥—Ä–∞_–º–∏–Ω" in final.columns:
        final["–í–Ω–µ_—è–¥—Ä–∞_–º–∏–Ω"] = final["–í–Ω–µ_—è–¥—Ä–∞_–º–∏–Ω"].fillna(0).astype(int)

    cols_order = [
        "–§–ò–û",
        "–î–∞—Ç–∞",
        "–í—Ä–µ–º—è –ø—Ä–∏—Ö–æ–¥–∞",
        "–í—Ä–µ–º—è —É—Ö–æ–¥–∞",
        "–û–ø–æ–∑–¥–∞–Ω–∏–µ",
        "–û–±—â–µ–µ –≤—Ä–µ–º—è",
        "–í–Ω–µ –æ—Ñ–∏—Å–∞",
        "–í—ã—Ö–æ–¥—ã",
        "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –±–æ–ª–µ–µ 2 —á–∞—Å–æ–≤ –ø–æ–¥—Ä—è–¥",
        "–ò—Ç–æ–≥–æ –∑–∞ –¥–µ–Ω—å",
        "–ò—Ç–æ–≥–æ –∑–∞ –Ω–µ–¥–µ–ª—é",
        "–ù–µ–¥–æ—Ä–∞–±–æ—Ç–∫–∏",
        "–ü—Ä–∏—á–∏–Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è",
        "–í–Ω–µ_—è–¥—Ä–∞_–º–∏–Ω",
    ]
    for c in cols_order:
        if c not in final.columns:
            final[c] = ""

    final = final[cols_order].copy()
    
    # üîí –ú–∞—Å–∫–∏—Ä–æ–≤–∫–∞ –§–ò–û –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ (–°–æ—Ç—Ä—É–¥–Ω–∏–∫ 001, –°–æ—Ç—Ä—É–¥–Ω–∏–∫ 002, ...)
    unique_fios = final['–§–ò–û'].unique()
    fio_map = {fio: f"–°–æ—Ç—Ä—É–¥–Ω–∏–∫ {i+1:03d}" for i, fio in enumerate(unique_fios)}
    final['–§–ò–û'] = final['–§–ò–û'].map(fio_map)

    # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º –æ—Ç—á—ë—Ç–µ
    final = final.drop(columns=['–í–Ω–µ_—è–¥—Ä–∞_–º–∏–Ω'], errors='ignore')
    
    return final
